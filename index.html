<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <title>AR‰∫∫Áâ©„Éë„Éç„É´PoC</title>
  <style>
    body { margin: 0; overflow: hidden; }
    canvas { display: block; }
    #ui {
      position: absolute; top: 10px; left: 10px; z-index: 10;
      background: rgba(0,0,0,0.5); padding: 10px; border-radius: 5px;
    }
    #captureBtn { font-size: 1.2em; }
  </style>
</head>
<body>
  <div id="ui">
    <button id="captureBtn">üì∏ ‰∫∫Áâ©„Çí„Éë„Éç„É´Âåñ</button>
  </div>
  <video id="inputVideo" autoplay playsinline style="display:none;"></video>
  <canvas id="canvas" width="640" height="480" style="display:none;"></canvas>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/selfie_segmentation.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.152.2/build/three.min.js"></script>

  <script>
    const video = document.getElementById('inputVideo');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    let capturedImages = [];

    // Set up MediaPipe Selfie Segmentation
    const selfieSegmentation = new SelfieSegmentation.SelfieSegmentation({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}`,
    });
    selfieSegmentation.setOptions({ modelSelection: 1 });
    selfieSegmentation.onResults(onSegmentationResult);

    let currentFrame = null;
    async function onSegmentationResult(results) {
      ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);
      const mask = results.segmentationMask;
      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const data = imageData.data;
      ctx.drawImage(mask, 0, 0, canvas.width, canvas.height);
      const maskData = ctx.getImageData(0, 0, canvas.width, canvas.height).data;

      // apply mask
      for (let i = 0; i < data.length; i += 4) {
        const alpha = maskData[i] > 200 ? 255 : 0;
        data[i + 3] = alpha;
      }
      ctx.putImageData(imageData, 0, 0);

      // capture image
      const img = new Image();
      img.src = canvas.toDataURL();
      capturedImages.push(img);
      addPanelToScene(img);
    }

    // Setup camera
    const cameraUtils = new Camera(video, {
      onFrame: async () => {
        await selfieSegmentation.send({ image: video });
      },
      width: 640,
      height: 480,
    });
    cameraUtils.start();

    // Capture button
    document.getElementById('captureBtn').addEventListener('click', () => {
      selfieSegmentation.send({ image: video });
    });

    // Three.js AR-like scene
    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera(75, window.innerWidth/window.innerHeight, 0.1, 1000);
    const renderer = new THREE.WebGLRenderer({ alpha: true });
    renderer.setSize(window.innerWidth, window.innerHeight);
    document.body.appendChild(renderer.domElement);

    const light = new THREE.HemisphereLight(0xffffff, 0x444444, 1.0);
    scene.add(light);

    camera.position.z = 5;

    function addPanelToScene(image) {
      const texture = new THREE.Texture(image);
      texture.needsUpdate = true;
      const material = new THREE.MeshBasicMaterial({ map: texture, transparent: true });
      const geometry = new THREE.PlaneGeometry(2, 3);
      const mesh = new THREE.Mesh(geometry, material);
      mesh.position.set(Math.random() * 2 - 1, 0, -Math.random() * 3 - 1);
      scene.add(mesh);
    }

    function animate() {
      requestAnimationFrame(animate);
      renderer.render(scene, camera);
    }
    animate();
  </script>
</body>
</html>
